{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d639ea0f",
   "metadata": {},
   "source": [
    "<h1>Classification Analysis</h1>\n",
    "\n",
    "<h1>A brief description of the code</h1>\n",
    "\n",
    "The following script uses the data set Game of Thrones, GoT, to build a classification model that is able to determine if a character is alive or not.\n",
    "\n",
    "Errors/Bugs identified as of December 5, 2021: None.\n",
    "\n",
    "<h1> Preparation and exploration of the data</h1>\n",
    "\n",
    "All necessary packages are loaded as well as some user defined functions and the data set, displaying the first 5 rows to understand the formatting of the data and its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas                  as pd                           # data science essentials\n",
    "import numpy                   as np                           # mathematical essentials\n",
    "import seaborn                 as sns                          # enhanced data viz\n",
    "import matplotlib.pyplot       as plt                          # data visualization\n",
    "import statsmodels.formula.api as smf                          # logistic regression\n",
    "import gender_guesser.detector as gender                       # guess gender based on first name\n",
    "from sklearn.model_selection import train_test_split           # train-test split\n",
    "from sklearn.linear_model    import LogisticRegression         # logistic regression\n",
    "from sklearn.metrics         import confusion_matrix           # confusion matrix\n",
    "from sklearn.metrics         import roc_auc_score              # auc score\n",
    "from sklearn.neighbors       import KNeighborsClassifier       # KNN for classification\n",
    "from sklearn.neighbors       import KNeighborsRegressor        # KNN for regression\n",
    "from sklearn.preprocessing   import StandardScaler             # standard scaler\n",
    "from sklearn.tree            import DecisionTreeClassifier     # classification trees\n",
    "from sklearn.tree            import plot_tree                  # tree plots\n",
    "from sklearn.model_selection import RandomizedSearchCV         # hyperparameter tuning\n",
    "from sklearn.metrics         import make_scorer                # customizable scorer\n",
    "from sklearn.ensemble        import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble        import GradientBoostingClassifier # gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc045ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined functions\n",
    "\n",
    "########################################\n",
    "#              mv_flagger              #\n",
    "########################################\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'COLUMN_NAME_unknown'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df[col+'_unknown'] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "########################################\n",
    "#           optimal_neighbors          #\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "#               visual_cm              #\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67267286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data types with a dictionary\n",
    "data_types = {\"culture\" : str}\n",
    "\n",
    "# loading data\n",
    "file = './GOT_character_predictions.xlsx'\n",
    "\n",
    "got = pd.read_excel(io         = file,\n",
    "                    header     = 0,\n",
    "                    sheet_name = 0,\n",
    "                    dtype      = data_types)\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "#got.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2ad4f",
   "metadata": {},
   "source": [
    "<h2>Understanding the variables</h2>\n",
    "\n",
    "The GOT dictionary is loaded to provided a better understanding of the variables and identify if there is, if any, irrelevant features for determining if the characters are alive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8100de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pulling up data dictionary\n",
    "#got_description = pd.read_excel('GOT_data_dictionary.xlsx')\n",
    "\n",
    "\n",
    "# displaying the data dictionary\n",
    "#got_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08524c95",
   "metadata": {},
   "source": [
    "<h2>Dropping columns</h2>\n",
    "\n",
    "The feature <em>S.No</em> will be dropped as it is an ordinal variables and works like an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping order of character appearance\n",
    "got = got.drop(labels = \"S.No\", \n",
    "               axis   = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946ddba",
   "metadata": {},
   "source": [
    "<h2>Missing values</h2>\n",
    "\n",
    "The following step is checking the missing values of the dataset. First the data was checked in therm or amount of missing values, and then it was checked by percentage of missing values per feature as to establish a strategy for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6144f",
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking each feature for missing values\n",
    "got.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf234fe8",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# checking percentage of missing values\n",
    "got.isnull().mean().round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e193e9",
   "metadata": {},
   "source": [
    "<h2>Flagging values</h2>\n",
    "\n",
    "As the existence of missing values might be insightful, all of them will be flagged before moving forward with any imputation strategy of dropping features due to low domain Knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57475ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the mv_flagger function\n",
    "got = mv_flagger(df = got)\n",
    "\n",
    "# checking results\n",
    "#got.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db39927",
   "metadata": {},
   "source": [
    "<h2>Missing values strategies and anomalies</h2>\n",
    "<br>\n",
    "\n",
    "1. Relationship between missing values:\n",
    "\n",
    "    * <strong>dateOfBirth</strong> has the the same amount of missing values as <strong>age</strong>\n",
    "    * <strong>mother</strong> has the the same amount of missing values as <strong>isAliveMother</strong>\n",
    "    * <strong>father</strong> has the the same amount of missing values as <strong>isAliveFather</strong>\n",
    "    * <strong>heir</strong> has the the same amount of missing values as <strong>isAliveHeir</strong>\n",
    "    * <strong>spouse</strong> has the the same amount of missing values as <strong>isAliveSpouse</strong>\n",
    "    <br>\n",
    "    \n",
    "Therefore, it can be inferred that the second featured is calculated based on the first one, meaning that they are strongly related and including both variables in the model will add multicollinearity to it.\n",
    "<br><br>\n",
    "\n",
    "2. Strategies for related missing values:\n",
    "    * <strong>dateOfBirth</strong>: drop feature as well as the related flagged feature, <strong>dateOfBirth_unknown</strong>\n",
    "    * <strong>age</strong>:\n",
    "        * fill missing values with mean by gender and title or noble status.\n",
    "        * drop related flagged feature, <strong>age_unknown</strong>\n",
    "        * It will be necessary to develop a new feature for gender. \n",
    "    * <strong>mother</strong>: drop feature, insufficient domain knowledge.\n",
    "    * <strong>isAliveMother</strong>: \n",
    "        * drop feature, insufficient domain knowledge.\n",
    "        * drop related flagged feature, <strong>isAliveFather_unknown</strong>\n",
    "    * <strong>father</strong>: drop feature, insufficient domain knowledge.\n",
    "    * <strong>isAliveFather</strong>: \n",
    "        * drop feature, insufficient domain knowledge.\n",
    "        * drop related flagged feature, <strong>isAliveFather_unknown</strong>\n",
    "    * <strong>heir</strong>: drop feature, insufficient domain knowledge.\n",
    "    * <strong>isAliveHeir</strong>: \n",
    "        * drop feature, insufficient domain knowledge.\n",
    "        * drop related flagged feature, <strong>isAliveHeir_unknown</strong>\n",
    "    * <strong>spouse</strong>: drop feature, insufficient domain knowledge.\n",
    "    * <strong>isAliveSpouse</strong>: \n",
    "        * drop feature, insufficient domain knowledge.\n",
    "        * drop related flagged feature, <strong>isAliveSpouse_unknown</strong>\n",
    "    <br><br><br>\n",
    "\n",
    "3. Other missing values:\n",
    "    * <strong>title</strong>: drop feature, insufficient domain knowledge.\n",
    "    * <strong>house</strong>: impute missing values according to character's last name, otherwise create a \"unknown\" category.\n",
    "    * <strong>culture</strong>: analyze if subcategories can be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f285ab1",
   "metadata": {},
   "source": [
    "<h2>Creating first and last name features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6069b",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# STEP 1: splitting to obtain family name\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each character name\n",
    "for index, col in got.iterrows():\n",
    "    \n",
    "    # splitting name at space ''\n",
    "    split_family_name = got.loc[index, 'name'].rsplit(sep      = ' ',\n",
    "                                                      maxsplit = 1)\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_family_name)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a new DataFrame \n",
    "family_name_df = pd.DataFrame(placeholder_lst, \n",
    "                              columns = ['name_no', 'last_name'])\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "family_name_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379bedc",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# STEP 2: splitting to obtain first name\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each character name\n",
    "for index, col in got.iterrows():\n",
    "    \n",
    "    # splitting name at space ''\n",
    "    split_first_name = got.loc[index, 'name'].split(sep      = ' ', \n",
    "                                                    maxsplit = 1)\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_first_name)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a new DataFrame \n",
    "first_name_df = pd.DataFrame(placeholder_lst,\n",
    "                             columns = ['first_name', 'no_familyname'])\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "first_name_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: concatenating with original DataFrame\n",
    "\n",
    "# concatenating first and last name only\n",
    "got = pd.concat([got, first_name_df.loc[ : , 'first_name'] , family_name_df.loc[ : , 'last_name']], \n",
    "                axis = 1)\n",
    "\n",
    "# droping original name feature\n",
    "got = got.drop(labels = 'name', \n",
    "               axis   = 1)\n",
    "\n",
    "# displaying the results\n",
    "got.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416f055",
   "metadata": {},
   "source": [
    "<h2>Creating and one-hot encoding a gender feature</h2>\n",
    "\n",
    "<h3>Creating gender feature</h3>\n",
    "\n",
    "The necessary package to create the feature were imported, and the guesses were put into a list to be used for hardcode the gender feature and comment out the gender guesser process as a measure to reduce the processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing gender_guesser\n",
    "#pip install gender_guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963beba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# guessing gender based on first name\n",
    "\n",
    "# placeholder list\n",
    "#placeholder_lst = []\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in got['first_name']:\n",
    "#    guess = gender.Detector().get_gender(name)\n",
    "#    print(guess)\n",
    "#    placeholder_lst.append(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc10c77f",
   "metadata": {},
   "source": [
    "The results from the list created before were printed in order to directly use the output for harcoding the gender variable and add it to the original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c6098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(placeholder_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b0ff8",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# creating list for gender\n",
    "gender_lts = ['unknown', 'unknown', 'andy', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'andy', 'andy', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'female', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'andy', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_female', 'female', 'unknown', 'mostly_female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'female', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'male', 'male', 'male', 'unknown', 'female', 'female', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'male', 'female', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'male', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'female', 'mostly_female', 'female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'mostly_male', 'unknown', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'andy', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown']\n",
    "\n",
    "# converting list into a series\n",
    "got['gender_guess'] = pd.Series(gender_lts)\n",
    "\n",
    "\n",
    "# checking results\n",
    "#got.head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8960048",
   "metadata": {},
   "source": [
    "<h3>One-hot encoding gender feature</h3>\n",
    "\n",
    "It is necessary to convert the gender feature as it is a categorical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ed4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding variables\n",
    "one_hot_gender_guess = pd.get_dummies(got['gender_guess'])\n",
    "\n",
    "# joining codings together\n",
    "got = got.join(other = [one_hot_gender_guess])\n",
    "\n",
    "# checking results\n",
    "#got.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062e675",
   "metadata": {},
   "source": [
    "<h3>Creating sub-categories for gender feature</h3>\n",
    "\n",
    "Gender has 6 categories, and 3 of them has less than 100 observations, therefore the categories will be feature engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76963485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting frecuency of gender guesses\n",
    "got['gender_guess'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c398b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# creating total female feature\n",
    "got['isFemale']      = (got['female']  + got['mostly_female'])\n",
    "\n",
    "# creating total male feature\n",
    "got['isMale']        = (got['male']    + got['mostly_male'])\n",
    "\n",
    "# creating total undetermined gender feature\n",
    "got['genderUndet']   = (got['unknown'] + got['andy'])\n",
    "\n",
    "\n",
    "# dropping variables feature engineering\n",
    "got = got.drop(labels = ['gender_guess', 'female', 'mostly_female', 'male', 'mostly_male', 'unknown', 'andy'], \n",
    "               axis   = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7071233",
   "metadata": {},
   "source": [
    "<h2>Dropping features</h2>\n",
    "\n",
    "Features were dropped per the strategy estated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping date of birth related variables\n",
    "got = got.drop(labels = ['dateOfBirth', 'dateOfBirth_unknown'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping mother related variables\n",
    "got = got.drop(labels = ['mother', 'isAliveMother', 'isAliveMother_unknown'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping father related variables\n",
    "got = got.drop(labels = ['father', 'isAliveFather', 'isAliveFather_unknown'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping heir related variables\n",
    "got = got.drop(labels = ['heir', 'isAliveHeir', 'isAliveHeir_unknown'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping spouse related variables\n",
    "got = got.drop(labels = ['spouse', 'isAliveSpouse', 'isAliveSpouse_unknown'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping additional variables\n",
    "got = got.drop(labels = ['age_unknown', 'title'], \n",
    "               axis   = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5c8ee",
   "metadata": {},
   "source": [
    "<h2>Imputing missing values for age</h2>\n",
    "\n",
    "There are 2 observations with age below than 0, meaning that the characters have not been born yet.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccb946",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "got['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da586d",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "(got['age'] < 0).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking age by categories\n",
    "print(f\"\"\"\n",
    "Mean Age:                     {round(got.loc[ : , 'age'].mean(),1)}\n",
    "Mean Born Characters Age:     {round(got.loc[ : , 'age'][got['age'] > 0].mean(),1)}\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "Mean Female Age:              {round(got.loc[ : , 'age'][got['age'] > 0][got['isFemale']      == 1].mean(),1)}\n",
    "Mean Male Age:                {round(got.loc[ : , 'age'][got['age'] > 0][got['isMale']        == 1].mean(),1)}\n",
    "Mean Undetermined Age:        {round(got.loc[ : , 'age'][got['age'] > 0][got['genderUndet']   == 1].mean(),1)}\n",
    "\n",
    "-------------------------------------------\n",
    "\n",
    "Mean Title Age:               {round(got.loc[ : , 'age'][got['age'] > 0][got['title_unknown'] == 0].mean(),1)}\n",
    "Mean NOT Title Age:           {round(got.loc[ : , 'age'][got['age'] > 0][got['title_unknown'] == 1].mean(),1)}\n",
    "\n",
    "Mean Noble Age:               {round(got.loc[ : , 'age'][got['age'] > 0][got['isNoble']       == 1].mean(),1)}\n",
    "Mean NOT Noble Age:           {round(got.loc[ : , 'age'][got['age'] > 0][got['isNoble']       == 0].mean(),1)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41863a3d",
   "metadata": {},
   "source": [
    "Checking the ages by categories shows that female average age is lower than male and undetermined gender, and these last two have a similar average age.\n",
    "<br><br>\n",
    "In addition, the average age by having a title or a noble status are virtually the same, therefore <em>isNoble</em> will be user to fill the missing values in age and since this feature has no missing values in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values for age\n",
    "\n",
    "# storing average age for noble female\n",
    "noble_female_avg_age            = round(got.loc[ : , 'age']\\\n",
    "                                        [got['isFemale'] == 1]\\\n",
    "                                        [got['isNoble']  == 1].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "# storing average age for noble male\n",
    "noble_male_avg_age              = round(got.loc[ : , 'age']\\\n",
    "                                        [got['isMale']     == 1]\\\n",
    "                                        [got['isNoble']    == 1].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "# storing average age for noble undetermined gender\n",
    "noble_undetermined_avg_age      = round(got.loc[ : , 'age']\\\n",
    "                                        [got['genderUndet'] == 1]\\\n",
    "                                        [got['isNoble'] == 1].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "\n",
    "# storing average age for NOT noble female\n",
    "notNoble_female_avg_age         = round(got.loc[ : , 'age']\\\n",
    "                                        [got['isFemale'] == 0]\\\n",
    "                                        [got['isNoble'] == 0].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "# storing average age for NOT noble male\n",
    "notNoble_male_avg_age           = round(got.loc[ : , 'age']\\\n",
    "                                        [got['isMale'] == 0]\\\n",
    "                                        [got['isNoble'] == 0].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "# storing average age for NOT noble undetermined gender\n",
    "notNoble_undetermined_avg_age   = round(got.loc[ : , 'age']\\\n",
    "                                        [got['genderUndet'] == 0]\\\n",
    "                                        [got['isNoble'] == 0].mean(),\n",
    "                                        ndigits = 1)\n",
    "\n",
    "\n",
    "# imputing missing values for age\n",
    "for index, val in got.iterrows():\n",
    "\n",
    "    \n",
    "    # noble female\n",
    "    if str(got.loc[index, 'age']).lower()    == 'nan'    and \\\n",
    "           got.loc[index, 'isFemale']        == 1        and \\\n",
    "           got.loc[index, 'isNoble']         == 1:\n",
    "        \n",
    "           got.loc[index, 'age'] = noble_female_avg_age\n",
    "            \n",
    "    \n",
    "\n",
    "    # noble males\n",
    "    elif str(got.loc[index, 'age']).lower()    == 'nan'  and \\\n",
    "             got.loc[index, 'isMale']          == 1      and \\\n",
    "             got.loc[index, 'isNoble']         == 1:\n",
    "        \n",
    "             got.loc[index, 'age'] = noble_male_avg_age\n",
    "\n",
    "            \n",
    "            \n",
    "    # noble undetermined gender\n",
    "    elif str(got.loc[index, 'age']).lower()    == 'nan'  and \\\n",
    "             got.loc[index, 'genderUndet']     == 1      and \\\n",
    "             got.loc[index, 'isNoble']         == 1:\n",
    "        \n",
    "             got.loc[index, 'age'] = noble_undetermined_avg_age\n",
    "\n",
    "\n",
    "    \n",
    "    # not noble female\n",
    "    elif str(got.loc[index, 'age']).lower()    == 'nan'    and \\\n",
    "             got.loc[index, 'isFemale']        == 1        and \\\n",
    "             got.loc[index, 'isNoble']         == 0:\n",
    "        \n",
    "             got.loc[index, 'age'] = notNoble_female_avg_age\n",
    "\n",
    "            \n",
    "    # not noble males\n",
    "    elif str(got.loc[index, 'age']).lower()    == 'nan'  and \\\n",
    "             got.loc[index, 'isMale']          == 1      and \\\n",
    "             got.loc[index, 'isNoble']         == 0:\n",
    "        \n",
    "             got.loc[index, 'age'] = notNoble_male_avg_age\n",
    "\n",
    "            \n",
    "    # not noble undetermined gender\n",
    "    elif str(got.loc[index, 'age']).lower()    == 'nan'  and \\\n",
    "             got.loc[index, 'genderUndet']     == 1      and \\\n",
    "             got.loc[index, 'isNoble']         == 0:\n",
    "        \n",
    "             got.loc[index, 'age'] = notNoble_undetermined_avg_age\n",
    "            \n",
    "\n",
    "# ensuring all missing values for age are filled\n",
    "print(f\"Remaining missing values for age: {got.loc[ :, 'age'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1f2c",
   "metadata": {},
   "source": [
    "<h2>Imputing missing values for house</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5384e1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# converting house observations into. lowercase\n",
    "got['house'] = got['house'].str.lower()\n",
    "\n",
    "#checking hourse frecuency \n",
    "got['house'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4ca85",
   "metadata": {},
   "source": [
    "In order to use the character's last name for imputing missing values, the missing values in <em>last_name</em> will be filled as \"unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values in last name\n",
    "got['last_name'] = got['last_name'].fillna('unknown')\n",
    "\n",
    "# converting last_name observations into. lowercase\n",
    "got['last_name'] = got['last_name'].str.lower()\n",
    "\n",
    "# ensuring all missing values for last_name are filled\n",
    "print(f\"Remaining missing values for last name: {got.loc[ :, 'last_name'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating categories for houses and one-hot encoding them\n",
    "\n",
    "# creating house_frey category\n",
    "got['night_watch']     = np.where((got['house'] == \"\"\"night's watch\"\"\"),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['night_watch'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_frey category\n",
    "got['house_frey']      = np.where(got['last_name'].str.contains('frey') |\\\n",
    "                                  got['house'].str.contains('frey'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_frey'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_stark category\n",
    "got['house_stark']     = np.where(got['last_name'].str.contains('stark') |\\\n",
    "                                  got['house'].str.contains('stark'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print (got['house_stark'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_targaryen category\n",
    "got['house_targaryen'] = np.where(got['last_name'].str.contains('targaryen') |\\\n",
    "                                  got['house'].str.contains('targaryen'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_targaryen'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_lannister category\n",
    "got['house_lannister'] = np.where(got['last_name'].str.contains('lannister') |\\\n",
    "                                  got['house'].str.contains('lannister'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_lannister'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_greyjoy category\n",
    "got['house_greyjoy']   = np.where(got['last_name'].str.contains('greyjoy') |\\\n",
    "                                  got['house'].str.contains('greyjoy'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_greyjoy'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_tyrell category\n",
    "got['house_tyrell']    = np.where(got['last_name'].str.contains('tyrell') |\\\n",
    "                                  got['house'].str.contains('tyrell'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_tyrell'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# creating house_tyrell category\n",
    "got['house_martell']   = np.where(got['last_name'].str.contains('martell') |\\\n",
    "                                  got['house'].str.contains('martell'),1,0)\n",
    "\n",
    "# checking frecuency\n",
    "print(got['house_martell'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25652fdc",
   "metadata": {},
   "source": [
    "<h2>Dropping remaining columns</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1367484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping categorical features that will not be used\n",
    "got = got.drop(labels = ['culture', 'house', 'house_unknown', 'first_name', 'last_name'], \n",
    "               axis   = 1)\n",
    "\n",
    "# dropping stratum for categorical variables\n",
    "got = got.drop(labels = ['genderUndet'], \n",
    "               axis   = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad158fa7",
   "metadata": {},
   "source": [
    "<h1>Train and testing sets</h1>\n",
    "\n",
    "<h2>Correlation analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "got_corr = got.corr().round(2)\n",
    "\n",
    "got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37761468",
   "metadata": {},
   "source": [
    "<h2>Stratifying the response variable</h2> \n",
    "\n",
    "The following will be done to preserve the balance of the response variable in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f431c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "got.loc[ : ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c422fa",
   "metadata": {},
   "source": [
    "<h2>Train and testing sets for statsmodels</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8846a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "got_data = got.drop(labels = 'isAlive', \n",
    "                    axis   = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "got_target = got.loc[ : , 'isAlive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "got_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking valance preservation\n",
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05319690",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all variables in data_data\n",
    "#for val in got_data:\n",
    "#    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96aad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic = smf.logit(formula = \"\"\"isAlive ~ book4_A_Feast_For_Crows\"\"\",\n",
    "                           data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413d240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic = smf.logit(formula = \"\"\"isAlive ~ book1_A_Game_Of_Thrones + \n",
    "                                                 book2_A_Clash_Of_Kings + \n",
    "                                                 book3_A_Storm_Of_Swords + \n",
    "                                                 book4_A_Feast_For_Crows + \n",
    "                                                 book5_A_Dance_with_Dragons + \n",
    "                                                 isMarried + \n",
    "                                                 isNoble + \n",
    "                                                 age + \n",
    "                                                 numDeadRelations + \n",
    "                                                 popularity + \n",
    "                                                 title_unknown + \n",
    "                                                 culture_unknown + \n",
    "                                                 mother_unknown + \n",
    "                                                 father_unknown + \n",
    "                                                 heir_unknown + \n",
    "                                                 spouse_unknown + \n",
    "                                                 isFemale + \n",
    "                                                 isMale + \n",
    "                                                 night_watch + \n",
    "                                                 house_frey + \n",
    "                                                 house_stark + \n",
    "                                                 house_targaryen + \n",
    "                                                 house_lannister + \n",
    "                                                 house_greyjoy + \n",
    "                                                 house_tyrell + \n",
    "                                                 house_martell\"\"\",\n",
    "                           data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56785df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic = smf.logit(formula = \"\"\"isAlive ~ book1_A_Game_Of_Thrones + \n",
    "                                                 book2_A_Clash_Of_Kings + \n",
    "                                                 book4_A_Feast_For_Crows +\n",
    "                                                 popularity + \n",
    "                                                 house_targaryen +\n",
    "                                                 house_tyrell\n",
    "                                                 \"\"\",\n",
    "                           data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_logistic = logistic.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329d0f4",
   "metadata": {},
   "source": [
    "<h1>Logistic classification model</h1>\n",
    "\n",
    "The upcoming models will use 2 candidate model's explanatory variables as follows, <em>logit_full</em> includes all the explanatory variables after they have been feature engineered and <em>logit_sig</em> includes only the variables with statistically significant for the previous logit regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb75e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', \n",
    "                   'book3_A_Storm_Of_Swords', 'book4_A_Feast_For_Crows', \n",
    "                   'book5_A_Dance_with_Dragons', 'isMarried', 'isNoble', \n",
    "                   'age', 'numDeadRelations', 'popularity', 'title_unknown', \n",
    "                   'culture_unknown', 'mother_unknown', 'father_unknown',\n",
    "                   'heir_unknown', 'spouse_unknown', 'isFemale', 'isMale',\n",
    "                   'night_watch', 'house_frey', 'house_stark', \n",
    "                   'house_targaryen', 'house_lannister', 'house_greyjoy', \n",
    "                   'house_tyrell', 'house_martell'],\n",
    " \n",
    " # significant variables only\n",
    " 'logit_sig'    : ['book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', \n",
    "                   'book4_A_Feast_For_Crows', 'popularity', 'house_targaryen',\n",
    "                   'house_tyrell'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70870af4",
   "metadata": {},
   "source": [
    "<h2>Building a logistic regression model in scikit-learn</h2>\n",
    "\n",
    "The regression model will be build using <em>logit_sig</em> as explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edf223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the significant model\n",
    "got_data   =  got.loc[ : , candidate_dict['logit_sig']]\n",
    "got_target =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "confusion_matrix(y_true = y_test,\n",
    "                 y_pred = logreg_pred)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, \n",
    "                             y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "#visual_cm(true_y = y_test,\n",
    "#          pred_y = logreg_pred,\n",
    "#          labels = ['Dead', 'Alive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(got[candidate_dict['logit_sig']].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf88df",
   "metadata": {},
   "source": [
    "<strong>Logistic Regression Comments:</strong>\n",
    "<br>\n",
    "\n",
    "The accuracy of the model increased for the testing set, however, the testing gap is above 0.05, so it could infer that the model is slightly overfitted.\n",
    "<br>\n",
    "\n",
    "In addition, since the AUC score is below 0.075, the analysis will continue to check the performance of other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e77c68",
   "metadata": {},
   "source": [
    "<h1>Classification Trees (CART Models)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')\n",
    "        \n",
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances_full(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train_full.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2afe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "#plot_feature_importances(pruned_tree_fit,\n",
    "#                         train = x_train,\n",
    "#                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca0c79",
   "metadata": {},
   "source": [
    "<strong>Comments on Feature Importance</strong>\n",
    "\n",
    "- Popularity</em> and <em>book4_A_Feast_For_Crows</em> are the most important features in terms of splitting the data into nodes.\n",
    "\n",
    "- house_tyrell</em> and <em>book1_A_Game_Of_Thrones</em> are the second best pair of most important features in terms of splitting the data into nodes.\n",
    "    \n",
    "- house_targaryen</em> and <em>book2_A_Clash_Of_Kings</em> seems to not be important features in terms of splitting the data into nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8bc36",
   "metadata": {},
   "source": [
    "<h1>Classification Modeling with KNN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8746456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the optimal number of neighbors\n",
    "#opt_neighbors = optimal_neighbors(x_data        = got_data,\n",
    "#                                  y_data        = got_target,\n",
    "#                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a391b",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br><br>\n",
    "        The optimal number of neighbors is: 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69634575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(got_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(got_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = 18)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d058f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "#visual_cm(true_y = y_test,\n",
    "#          pred_y = knn_pred,\n",
    "#          labels = ['Dead', 'Alive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c829757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'FINAL MODEL - KNN Tree',\n",
    "                          'Training Accuracy'  : knn_train_score,\n",
    "                          'Testing Accuracy'   : knn_test_score, \n",
    "                          'AUC Score'          : knn_auc_score,\n",
    "                          'Confusion Matrix'   : (knn_tree_tn, \n",
    "                                                  knn_tree_fp, \n",
    "                                                  knn_tree_fn, \n",
    "                                                  knn_tree_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618057c2",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression with Default Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce456dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model with default values\n",
    "lr_default = LogisticRegression(solver = 'lbfgs',\n",
    "                                C = 1.0,\n",
    "                                warm_start = False,\n",
    "                                random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "lr_default_fit = lr_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_default_pred = lr_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# SCORING with AUC\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_default_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = lr_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = lr_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = lr_default_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33fb85",
   "metadata": {},
   "source": [
    "<h2>Hyperparameter Tuning with RandomizedSearchCV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582789c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#C_range          = np.arange(0.1, 5.0, 0.1)\n",
    "#warm_start_range = [True, False]\n",
    "#solver_range     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'C'          : C_range,\n",
    "#              'warm_start' : warm_start_range,\n",
    "#              'solver'     : solver_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                              max_iter     = 1000) # increased for convergence\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                 param_distributions = param_grid, # parameters to tune\n",
    "#                                 cv                  = 3,          # how many folds in cross-validation\n",
    "#                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "#                                 random_state        = 219,        # starting point for random sequence\n",
    "#                                 scoring = make_scorer(\n",
    "#                                           roc_auc_score,\n",
    "#                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#lr_tuned_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "#print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdad5a9",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- Tuned Parameters  : {'warm_start': True, 'solver': 'sag', 'C': 4.9}\n",
    "- Tuned CV AUC      : 0.5971"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbad49c",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression with Tuned Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a97aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the best estimator for the model\n",
    "#lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd76994",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- LogisticRegression(C=4.9, max_iter=1000, random_state=219, solver='sag', warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C            = 4.9,\n",
    "                              warm_start   = True,\n",
    "                              solver       = 'sag',\n",
    "                              max_iter     = 1000,\n",
    "                              random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the model to the full dataset\n",
    "lr_tuned.fit(got_data, got_target) # this is ok because already tuned\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1143c9",
   "metadata": {},
   "source": [
    "<h2>Hyperparameter Tuning on Classification Trees</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#criterion_range = ['gini', 'entropy']\n",
    "#splitter_range  = ['best', 'random']\n",
    "#depth_range     = np.arange(1, 25, 1)\n",
    "#leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_range,\n",
    "#              'splitter'         : splitter_range,\n",
    "#              'max_depth'        : depth_range,\n",
    "#              'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "#tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                   param_distributions   = param_grid,\n",
    "#                                   cv                    = 3,\n",
    "#                                   n_iter                = 1000,\n",
    "#                                   random_state          = 219,\n",
    "#                                   scoring = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#tuned_tree_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c347d7",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- Tuned Parameters  : {'splitter': 'best', 'min_samples_leaf': 4, 'max_depth': 7, 'criterion': 'gini'}\n",
    "- Tuned Training AUC: 0.6744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676316b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 4,\n",
    "                                    max_depth        = 7,\n",
    "                                    criterion        = 'gini',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab51fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6154a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae87c49",
   "metadata": {},
   "source": [
    "<h2>Ensemble Modeling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the logit_sig variables\n",
    "got_data_full   =  got.loc[ : , candidate_dict['logit_full']]\n",
    "got_target_full =  got.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# train/test split\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = train_test_split(\n",
    "            got_data_full,\n",
    "            got_target_full,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100, #number of trees in the forest\n",
    "                                    criterion        = 'gini', #quality of a split\n",
    "                                    max_depth        = None, #depth of the tree\n",
    "                                    min_samples_leaf = 1, #min required to be a leaf node\n",
    "                                    bootstrap        = True, #if bootstrap will be used when building trees\n",
    "                                    warm_start       = False, #fit whole new model\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61af0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train_full, y_train_full)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test_full)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train_full, y_train_full).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test_full, y_test_full).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_full,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e80bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "#plot_feature_importances_full(rf_default_fit,\n",
    "#                         train = x_train_full,\n",
    "#                         export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b365997",
   "metadata": {},
   "source": [
    "<strong>Comments on Feature Importance</strong>\n",
    "\n",
    "- Popularity</em> and <em>age</em> are the most important features in terms of splitting the data into nodes.\n",
    "\n",
    "- book4_A_Feast_For_Crows </em>is the second best most important feature in terms of splitting the data into nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test_full, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e827bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train_full, y_train_full).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test_full, y_test_full).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test_full,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab993f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(x_train_full, y_train_full)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(x_test_full)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#estimator_range  = np.arange(100, 1100, 250)\n",
    "#leaf_range       = np.arange(1, 31, 10)\n",
    "#criterion_range  = ['gini', 'entropy']\n",
    "#bootstrap_range  = [True, False]\n",
    "#warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'n_estimators'     : estimator_range,\n",
    "#              'min_samples_leaf' : leaf_range,\n",
    "#              'criterion'        : criterion_range,\n",
    "#              'bootstrap'        : bootstrap_range,\n",
    "#              'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                               param_distributions = param_grid,\n",
    "#                               cv         = 3,\n",
    "#                               n_iter     = 1000,\n",
    "#                               scoring    = make_scorer(roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#forest_cv.fit(got_data_full, got_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111c1fd",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- Tuned Parameters  : {'warm_start': True, 'n_estimators': 100, 'min_samples_leaf': 1, 'criterion': 'entropy', 'bootstrap': False}\n",
    "- Tuned Training AUC: 0.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b26516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimators based on RandomizedSearchCV\n",
    "#forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c53d9c",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- RandomForestClassifier(bootstrap=False, criterion='entropy', random_state=219, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd94f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion        = 'entropy',\n",
    "                                      min_samples_leaf = 1,\n",
    "                                      n_estimators     = 100,\n",
    "                                      warm_start       = True,\n",
    "                                      bootstrap        = False,\n",
    "                                      random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(got_data_full, got_target_full)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test_full)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train_full, y_train_full).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test_full, y_test_full).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test_full,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train_full, y_train_full).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test_full, y_test_full).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test_full,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabbc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "plot_feature_importances_full(forest_tuned_fit,\n",
    "                         train = x_train_full,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test_full, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train_full, y_train_full).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test_full, y_test_full).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test_full,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05280de",
   "metadata": {},
   "source": [
    "<h2>Gradient Boosted Machines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train_full, y_train_full)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test_full)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train_full, y_train_full).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test_full, y_test_full).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_full,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test_full, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train_full, y_train_full).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test_full, y_test_full).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test_full,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_range        = np.arange(0.1, 2.2, 0.5)\n",
    "#estimator_range    = np.arange(100, 501, 25)\n",
    "#depth_range        = np.arange(2, 11, 2)\n",
    "#warm_start_range   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_range,\n",
    "#              'max_depth'     : depth_range,\n",
    "#              'n_estimators'  : estimator_range,\n",
    "#              'warm_start'    : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                           param_distributions = param_grid,\n",
    "#                           cv                  = 3,\n",
    "#                           n_iter              = 500,\n",
    "#                           random_state        = 219,\n",
    "#                           scoring             = make_scorer(roc_auc_score,\n",
    "#                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(got_data_full, got_target_full)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0fddd",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- Tuned Parameters  : {'warm_start': False, 'n_estimators': 325, 'max_depth': 6, 'learning_rate': 0.1}\n",
    "- Tuned Training AUC: 0.6796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69416f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the best estimator for the model\n",
    "#full_gbm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e0d58",
   "metadata": {},
   "source": [
    "<strong>Results from the previous code:</strong> \n",
    "<br>\n",
    "\n",
    "- GradientBoostingClassifier(max_depth=6, n_estimators=325, random_state=219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb33ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 0.1,\n",
    "                                       max_depth     = 6,\n",
    "                                       n_estimators  = 325,\n",
    "                                       warm_start    = False,\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(got_data_full, got_target_full)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test_full)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train_full, y_train_full).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test_full, y_test_full).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test_full,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test_full, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train_full, y_train_full).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test_full, y_test_full).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test_full,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4561095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined funciton displaying final model results\n",
    "def print_final_model(train_acc, test_acc, auc_score, tn, fp, fn, tp):\n",
    "    \n",
    "    \"\"\"\n",
    "Displays the final model results.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "possible_models: DF including the information por the possible.\n",
    "train_acc      : final training model accuracy.\n",
    "test_acc       : final testing model accuracy.\n",
    "auc            : final model AUC score.\n",
    "tn             : correctly predicted false values for the response variable.\n",
    "fp             : incorrectly predicted true values for the response variable.\n",
    "fn             : incorrectly predicted false values for the response variable.\n",
    "tp             : correctly predicted true values for the response variable.\n",
    "\"\"\"\n",
    "    \n",
    "    # printing final model results\n",
    "\n",
    "    print(f\"\"\"\n",
    "  Final Model:\n",
    "\n",
    "  Model        Train Score      Test Score      AUC Score\n",
    "  -----        -----------      ----------      ----------\n",
    "  Tuned GBM       {train_acc}          {test_acc}          {auc_score}\n",
    "\n",
    "                                                 |\n",
    "  True Negatives:          {tn}                    |  False Positives:         {fp}                   \n",
    "                                                 |\n",
    "  PREDICTED: Dead         (isAlive=0)            |  PREDICTED: Alive        (isAlive=1)\n",
    "  ACTUAL:    Dead         (isAlive=0)            |  ACTUAL:    Dead         (isAlive=0)\n",
    "                                                 |\n",
    "-------------------------------------------------|-----------------------------------------------\n",
    "                                                 |\n",
    "  False Negatives:           {fn}                   |  True Positives:         {tp}\n",
    "                                                 |  \n",
    "  PREDICTED: Dead         (isAlive=0)            |  PREDICTED: Dead         (isAlive=0)\n",
    "  ACTUAL:    Alive        (isAlive=1)            |  ACTUAL:    Alive        (isAlive=1)\n",
    "                                                 |  \n",
    "\n",
    "Candidate Models:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function\n",
    "print_final_model(knn_train_score, knn_test_score, knn_auc_score, \n",
    "                  knn_tree_tn, knn_tree_fp, knn_tree_fn, knn_tree_tp)\n",
    "\n",
    "# displaying all possible models.\n",
    "model_performance.sort_values(by = 'AUC Score',\n",
    "                              ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
